{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a358b1fe",
      "metadata": {
        "id": "a358b1fe"
      },
      "source": [
        "# Import package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "387b6148",
      "metadata": {
        "id": "387b6148"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92ddf298",
      "metadata": {
        "id": "92ddf298"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9ecdde4a",
      "metadata": {
        "id": "9ecdde4a"
      },
      "outputs": [],
      "source": [
        "class Config():\n",
        "    def __init__(self):\n",
        "        self.env_name = \"CartPole-v1\"\n",
        "        self.total_episode = 10\n",
        "        self.gamma = 0.997\n",
        "        self.num_action = 2\n",
        "        self.reuse_tree = False #reuse or build new tree. After first MCTS (for s0), we have tree for s1, ... We can reuse this tree or build new tree for s1, s2, ...\n",
        "        #You need set config.timeout or config.search_step to None and another to integer\n",
        "        self.timeout = None #each MCTS step will run until timeout (set config.timeout to None if you don't want limit by time)\n",
        "        self.search_step = 10 #each MCTS step will run config.search_step (set config.search_step to None if you want to run with time limit)\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d530f8de",
      "metadata": {
        "id": "d530f8de"
      },
      "source": [
        "# MCTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04d28eaf",
      "metadata": {
        "id": "04d28eaf"
      },
      "source": [
        "## Node\n",
        "The Node includes two main functions: init and get_score:\n",
        "- init:\n",
        "    - N: number of visits, initialized to 0\n",
        "    - V: sum of returns, initialized to 0\n",
        "    - children: None initially; children nodes will be added in the explore function\n",
        "    - parent: the parent node, or None if this is the root\n",
        "    - lead_action: the action that led to this node, or None if root\n",
        "    - num_action: number of possible actions\n",
        "    - env: a copy of the environment from the parent node’s env (or copy the main env if root)\n",
        "    - If lead_action exists: perform this action to get reward and done status\n",
        "    - Otherwise, set reward = 0 and done = False\n",
        "    - available_actions: the set of legal actions (equal to num_action), from which actions will be removed when children nodes are added\n",
        "- get_score:\n",
        "    - Calculate the score of the node using the formula:\n",
        "        - If the node is root, score = 0\n",
        "        - Otherwise: $score = \\frac{V}{N} + c \\sqrt\\frac{2\\ln(N_p)}{N}$\n",
        "    - Where $c = \\frac{1}{\\sqrt 2}$\n",
        "    - $N_p$ is the visit count of the parent node if the node has a parent, or the node’s own visit count if it is the root\n",
        "- is_explore: return True if node is explored:\n",
        "    - Have childrent (!= None)\n",
        "    - Is terminal state (done = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0770f5f7",
      "metadata": {
        "id": "0770f5f7"
      },
      "outputs": [],
      "source": [
        "class Node():\n",
        "    def __init__(self, num_action, base_env, parent = None, lead_action = None, state = None):\n",
        "        self.N = 0\n",
        "        self.V = 0.\n",
        "\n",
        "        self.children = None\n",
        "        self.parent = parent\n",
        "        self.lead_action = lead_action\n",
        "        self.num_action = num_action\n",
        "\n",
        "        self.env = copy.deepcopy(base_env)\n",
        "        if lead_action is not None:\n",
        "            self.state, self.reward, terminated, truncated, info = self.env.step(lead_action)\n",
        "            self.done = terminated or truncated\n",
        "        else:\n",
        "            self.done = False\n",
        "            self.reward = 0.\n",
        "            self.state = state\n",
        "        self.available_actions = set(list(range(num_action))) if not self.done else set()\n",
        "\n",
        "    def get_score(self):\n",
        "        if self.N == 0:\n",
        "            return 1e9\n",
        "\n",
        "        top_node = self\n",
        "        if top_node.parent is not None:\n",
        "            top_node = top_node.parent\n",
        "\n",
        "        c = 1. / np.sqrt(2)\n",
        "        V = self.V / self.N\n",
        "        return V + c * np.sqrt(2 * np.log(top_node.N) / self.N)\n",
        "\n",
        "    def is_explore(self):\n",
        "        return self.children and not self.done"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeca1cd1",
      "metadata": {
        "id": "aeca1cd1"
      },
      "source": [
        "## MCTS functions\n",
        "\n",
        "**simulate**: Perform a random play (rollout) for one episode and return the total reward of that episode.\n",
        "- Copy the environment state from the given node before simulation.\n",
        "\n",
        "**create_child**: create all chilrent for current node.\n",
        "\n",
        "**backpropagate**: backpropagate the return value up the tree.\n",
        "\n",
        "**find_explore_node**: Select a leaf node starting from the root by repeating:\n",
        "- Use the score function to select the best child node.\n",
        "- Move to that child node.\n",
        "- Stop when reaching a terminal node or unexplored node (**node.is_exlore**).\n",
        "\n",
        "**explore**:\n",
        "- Select a leaf node(**Select a leaf node**):\n",
        "- If stop at non terminal node:\n",
        "    - create all children for this node (**create_child**).\n",
        "- Perform simulation from this node to get a return value (**simulate**).\n",
        "- Backpropagate the return value up the tree (**backpropagate**).\n",
        "\n",
        "**select_action**: Choose the best action as the child node with the highest visit count (N)\n",
        "\n",
        "**mcts**:\n",
        "- Perform multiple explore steps.\n",
        "- Choose the best action as the child node with the highest visit count (N) (**select_action**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "75b3ccc4",
      "metadata": {
        "id": "75b3ccc4"
      },
      "outputs": [],
      "source": [
        "def simulate(node):\n",
        "    env = copy.deepcopy(node.env)\n",
        "    done = node.done\n",
        "    G = 0.\n",
        "    rewards = []\n",
        "    while not done:\n",
        "        action = np.random.choice(config.num_action)\n",
        "        _, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        rewards.append(reward)\n",
        "    for reward in reversed(rewards):\n",
        "        G = G * config.gamma + reward\n",
        "    env.close()\n",
        "    return G\n",
        "\n",
        "def create_child(node):\n",
        "    node.children = []\n",
        "    for action in range(config.num_action):\n",
        "        new_node = Node(config.num_action, node.env, node, action, None)\n",
        "        node.children.append(new_node)\n",
        "    return node\n",
        "\n",
        "def backpropagate(node, G):\n",
        "    while node:\n",
        "        node.N += 1\n",
        "        node.V += G\n",
        "        G = config.gamma * G + node.reward\n",
        "        node = node.parent\n",
        "\n",
        "def find_explore_node(explore_node):\n",
        "    current_node = explore_node\n",
        "    while current_node.children and not current_node.done:\n",
        "        children = current_node.children\n",
        "        actions_score = [child.get_score() for child in children]\n",
        "        max_score = max(actions_score)\n",
        "        best_children = [child for child, score in zip(children, actions_score) if score == max_score]\n",
        "        idx = np.random.choice(len(best_children))\n",
        "        current_node = best_children[idx]\n",
        "    return current_node\n",
        "\n",
        "def explore(explore_node):\n",
        "    current_node = find_explore_node(explore_node)\n",
        "\n",
        "    if current_node.children is None and not current_node.done:\n",
        "        current_node = create_child(current_node)\n",
        "\n",
        "    G = simulate(current_node)\n",
        "\n",
        "    backpropagate(current_node, G)\n",
        "\n",
        "def check_mcts(timeout, start_time, search_step, current_step):\n",
        "    if timeout is None:\n",
        "        return current_step < search_step\n",
        "    return datetime.now() - start_time < timedelta(seconds=timeout)\n",
        "\n",
        "def select_action(root_node):\n",
        "    children = root_node.children\n",
        "    Ns= [child.N for child in children]\n",
        "    max_N = max(Ns)\n",
        "    best_children = [child for child, action, N in zip(children, [child.lead_action for child in children], Ns) if N == max_N]\n",
        "    best_actions = [action for child, action, N in zip(children, [child.lead_action for child in children], Ns) if N == max_N]\n",
        "    best_child = best_children[0]\n",
        "    best_child.parent = None\n",
        "    best_child.lead_action = None\n",
        "    best_child.reward = 0.\n",
        "    best_child.done = False\n",
        "    return best_actions[0], best_child\n",
        "\n",
        "def mcts(root_state, root_env, timeout = 1, search_step = None, tree=None):\n",
        "    root_node = tree if (tree and config.reuse_tree) else Node(config.num_action, root_env, None, None)\n",
        "    start_time = datetime.now()\n",
        "    step = 0\n",
        "    while check_mcts(timeout, start_time, search_step, step):\n",
        "        explore(root_node)\n",
        "        step += 1\n",
        "    return select_action(root_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c97153b",
      "metadata": {
        "id": "3c97153b"
      },
      "source": [
        "# play and test episodes\n",
        "\n",
        "Play config.total_episode episodes and print the results. For each episode:\n",
        "- Reset the environment.\n",
        "- Repeat until the episode ends:\n",
        "    - Use the mcts function to find the best action.\n",
        "    - Perform this action in the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fcf0ce0",
      "metadata": {
        "id": "9fcf0ce0"
      },
      "outputs": [],
      "source": [
        "episode_rewards = []\n",
        "episode_steps = []\n",
        "episode_runtimes = []\n",
        "\n",
        "for episode in range(config.total_episode):\n",
        "    start_time = datetime.now()\n",
        "    env = gym.make(config.env_name, render_mode=\"rgb_array\")\n",
        "    state, info = env.reset()\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "    episode_step = 0\n",
        "    next_tree = None\n",
        "\n",
        "    while not done:\n",
        "        action, next_tree = mcts(state, env, config.timeout, config.search_step, next_tree)\n",
        "        state, reward, terminated, truncated, info = env.step(action)\n",
        "        episode_reward += reward\n",
        "        episode_step += 1\n",
        "        if episode_step % 100 == 0:\n",
        "            print(episode_step, episode_reward)\n",
        "        done = terminated or truncated\n",
        "\n",
        "    episode_rewards.append(episode_reward)\n",
        "    episode_steps.append(episode_step)\n",
        "    episode_runtimes.append(datetime.now() - start_time)\n",
        "    print(episode_reward, episode_runtimes[-1], \"\\n\")\n",
        "\n",
        "episode_rewards = np.array(episode_rewards)\n",
        "print(episode_rewards)\n",
        "print(episode_rewards.max(), episode_rewards.min(), episode_rewards.mean(), episode_rewards.std())\n",
        "print(max(episode_runtimes), min(episode_runtimes), np.mean(episode_runtimes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "g7hI0fUaGoX_",
      "metadata": {
        "id": "g7hI0fUaGoX_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gym",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
